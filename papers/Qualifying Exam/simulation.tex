
\section{Simulation}\label{sec:simulation}
% Simulation:
%%  Mean control results   (image and plot(s) )
%%  Variance Control      (image and plot(s) )
%%  Hybrid control   (image and plot(s) )

Our simulations use a Javascript port of \href{http://box2d.org/}{Box2D}, a popular 2D physics engine with support for rigid-body dynamics and fixed-time step simulation~\cite{catto2010box2d}.  All experiments ran on a Chrome web browser on a 2.6 GHz Macbook.  \href{https://github.com/aabecker/SwarmControlSandbox/blob/master/exampleControllers/BlockPushingIROS2015.html}{All code is available at}~\cite{Shahrokhi2015}.

\subsection{Controlling the mean position}

We control mean position with a PD controller that uses the mean position and mean velocity. Our control input is the global force applied to each robot:
\begin{align}
u_x &= K_{p}(x_{goal} - \bar{x}) + K_{d}(0-\bar{v}_x) \nonumber\\
u_y &= K_{p}(y_{goal}  - \bar{y}) + K_{d}(0-\bar{v}_y)  \label{eq:PDcontrolPosition}
\end{align}
here $K_{p}$ is the proportional gain, and $K_{d}$ is the derivative gain. We performed a parameter sweep to identify the best values.  Representative experiments are shown in Fig.~\ref{fig:gainvalues}. 100 robots were used and the maximum speed was 3 meters per second. As shown in Fig.~\ref{fig:gainvalues}, we can achieve an overshoot of 1\% and a  rise time of 1.52 s with $K_{p}= 4$, and  $K_{d} = 1$. Fig.~\ref{fig:meanVideo} shows an example of controlling mean position by making it trace the word ``SWARM".

\begin{figure}
\centering
\begin{overpic}[width = \columnwidth ]{gains.eps}
\end{overpic}
\vspace{-1em}
\caption{\label{fig:gainvalues} Tuning proportional ($K_p$, top) and derivative ($K_d$, bottom)  gain values in \eqref{eq:PDcontrolPosition} improves performance with $n = 100$ robots.
%\vspace{-2em}
}
\end{figure}

\begin{figure}
\centering
\begin{overpic}[width = \columnwidth* 2/3 ]{meanVideoSnapShot.png}
\end{overpic}
\vspace{0 em}
\caption{\label{fig:meanVideo} A frame from video attachment showing mean position control on a swarm of 200 robots. The mean position of the swarm traces ``SWARM"~\cite{ShivaVideo2015}. 
%\vspace{-2em}
}
\end{figure}


\subsection{Controlling the variance}
\begin{figure}
\centering
\begin{overpic}[width = \columnwidth] {brownianWpublish.eps}
\end{overpic}
\vspace{-1em}
\caption{\label{fig:varyBrownian} Increased noise results in more responsive variance control because stronger Brownian noise causes a faster increase of variance.
%\vspace{-2em}
}
\end{figure}

%cite the control law, explain experiment (number of robots, maximum speed, ).

For variance control we use the control law discussed in Section~\ref{sec:VarianceControl}.  Moving away from the wall and waiting is sufficient to increase variance because Brownian noise naturally disperses the swarm in such a way that the variance increases linearly~\cite{einstein1956investigations}.  If faster dispersion is needed, the swarm can be pushed through obstacles such as a diffraction grating or Pachinko board~\cite{Becker2013b}. %no need to worry about blocks in this controller.

The variance control law to regulate the variance to $\sigma^2_{ref}$ has three gains:
\begin{align}
u_x &= K_{p}(x_{goal}(\sigma^2_{ref}) - \bar{x}) - K_{d}\bar{v}_x + K_{i}(\sigma^2_{ref}-\sigma^2_{x}) \nonumber\\
u_y &= K_{p}(y_{goal}(\sigma^2_{ref})  - \bar{y}) - K_{d}\bar{v}_y + K_{i}(\sigma^2_{ref}-\sigma^2_{y}).  \label{eq:PDcontrolVariance}
\end{align}
In a slight abuse of notation we call the gain scaling the variance error $K_i$ because the variance, if unregulated, integrates over time.
Eq.~\eqref{eq:PDcontrolVariance} assumes the nearest wall is to the left of the robot at $x=0$, and chooses a reference goal position that in steady-state would have the correct variance according to \eqref{eq:VarianceUniformDistribution}:
\begin{align}
x_{goal}(\sigma^2_{ref}) = r + \sqrt{3\sigma^2_{ref}}
\end{align}
 If another wall is closer, the signs of $[K_p,K_i]$ are inverted, and the location $x_{goal}$ is translated.  Results are shown in Fig.~\ref{fig:varyBrownian}, with $K_{p,i,d} = [4,1,1]$.



%\todo{image showing control x variance and y-variance out of phase}


\subsection{Hybrid Control of mean and variance}

Fig. ~\ref{fig:hybrid} shows a simulation run of the hybrid controller in Alg.~\ref{alg:MeanVarianceControl} with 100 robots in a square workspace containing no internal obstacles. Fig.~\ref{fig:videoVar} shows the experiment of running the hybrid controller.

%\todo{plot showing 1.5 cycles of mean position, and a variance goal.  We might need a longer time}
\begin{figure}
\centering
\begin{overpic}[width = \columnwidth]{meanVariance4.eps}
\end{overpic}
\vspace{-1em}
\caption{\label{fig:hybrid} Simulation result with 100 robots under hybrid control Alg.~\ref{alg:MeanVarianceControl}, which  controls both the mean position (top) and variance (bottom). For ease of analysis, only $x$ position and variance are shown.
%\vspace{-2em}
}
\end{figure}

\begin{figure}
\centering
\begin{overpic}[width = \columnwidth * 2/3]{VideoSnapShot.png}
\end{overpic}
\vspace{-1em}
\caption{\label{fig:videoVar} A frame from video, using Alg.~\ref{alg:MeanVarianceControl} to control variance and mean position of a swarm of 200 robots~\cite{ShivaVideo2015}.
%\vspace{-2em}
}
\end{figure}

Algorithms \ref{alg:PosControl2Robots}, \ref{alg:XControl}, \ref{alg:YControl}, were implemented in Mathematica using point robots (radius = $0$).  All code is available at a public github repository~\cite{Shahrokhi2015GitHubShapeControl}.  Figs~\ref{fig:shapeControlMathematica1} and \ref{fig:shapeControlMathematica2} show the examples of the implementation of our algorithm. In both of these figures we have denoted the starting points and the destinations by small circles. However, destination points are surrounded by larger circles so as to be distinct from starting points. 

In each of these figures we have five snapshots of the running of our algorithm taken every quarter second. For the sake of brevity we have replaced straight moves (e.g. upward, downward, etc) with oblique moves that shows a combination of two moves simultaneously (e.g. left and down together). 

As we can see, in Fig.~\ref{fig:shapeControlMathematica1} $\Delta r_x$ is adjusted to $\Delta e_x$ in the second snapshot, i.e., at $t = t_1$ where $t_1<0.25$. The rest of the steps in this figure is dedicated to adjusting the $\Delta r_y$ to $\Delta e_y$. As it is clear from Fig.~\ref{fig:shapeControlMathematica1}, $\Delta r_y$ is also adjusted at $t = t_2$ where $0.75<t_2<1$. Finally, once $\Delta r_x$ and $\Delta r_y$ are adjusted, the algorithm gives a global input both of the robots so as to move them toward their corresponding destinations. This is happening in the time interval of $(t_2,1]$.

Similarly, in Fig.~\ref{fig:shapeControlMathematica2} we can see that the $\Delta r_x$ is adjusted in the third snapshot, i.e., at $t=t_3$ where $0.25<t_3<0.5$ and $\Delta r_y$ is adjusted in the last snapshot at $t=t_4$ where $0.75<t_4<1$. The final positioning steps are happening in the time interval of $(t_4,1]$.

As we pointed out earlier, adjusting each of $\Delta r_x$ and $\Delta r_y$ needs two iterations in the worst case. In other words, both of the Alg. \ref{alg:XControl} and Alg. \ref{alg:YControl} are executed two times in the worst case in positioning process of the robots. It is easy to see that we need two iterations of Alg. \ref{alg:XControl} only if $|\Delta e_x - \Delta s_x|>L$. Similarly we need two iterations of Alg. \ref{alg:YControl} only if $|\Delta e_y - \Delta s_y|>L$.



%\textcolor{red}{Shiva:  what is the complexity of this algorithm?  How many steps in the worst case?  When does worst case happen?}





\begin{figure*}
\centering
\renewcommand{\figwid}{0.4\columnwidth}
{\begin{overpic}[width =\figwid]{two_1.jpg}\put(45,75){$t$  = 0 s}
\end{overpic}
\begin{overpic}[width =\figwid]{two_2.jpg}\put(45,75){$t$  = 0.25 s}
\end{overpic}
\begin{overpic}[width =\figwid]{two_3.jpg}\put(45,75){$t$  = 0.5 s}
\end{overpic}
\begin{overpic}[width =\figwid]{two_4.jpg}\put(45,75){$t$  = 0.75 s}
\end{overpic}
\begin{overpic}[width =\figwid]{two_5.jpg}\put(45,75){$t$  = 1 s}
\end{overpic}}
\vspace{-1em}
\caption{\label{fig:shapeControlMathematica1}{Frames from an implementation of Alg.\ \ref{alg:PosControl2Robots}: two robot positioning using walls with infinite friction.
Robot initial positions are shown by a crosshair, and final positions by a circled crosshair.  Dashed lines show the shortest route if robots could be controlled independently.  The path given by  Alg.\ \ref{alg:PosControl2Robots} is shown with solid arrows.
}
%\vspace{-2em}
}
\end{figure*}

\begin{figure*}
\centering
\renewcommand{\figwid}{0.4\columnwidth}
{\begin{overpic}[width =\figwid]{one_1.jpg}\put(45,75){$t$ = 0 s}
\end{overpic}
\begin{overpic}[width =\figwid]{one_2.jpg}\put(45,75){$t$ = 0.25 s}
\end{overpic}
\begin{overpic}[width =\figwid]{one_3.jpg}\put(45,75){$t$  = 0.5 s}
\end{overpic}
\begin{overpic}[width =\figwid]{one_4.jpg}\put(45,75){$t$  = 0.75 s}
\end{overpic}
\begin{overpic}[width =\figwid]{one_5.jpg}\put(45,75){$t$  = 1 s}
\end{overpic}}
\vspace{-1em}
\caption{\label{fig:shapeControlMathematica2}{Two robot positioning: switching positions using walls with infinite friction.  Code available at~\cite{Shahrokhi2015GitHubShapeControl}.}
%\vspace{-2em}
}
\end{figure*}







