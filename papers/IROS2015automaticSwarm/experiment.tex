
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Block-Pushing Results}\label{sec:expResults}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The experimental section compares the results of our hybrid hysteresis-based controller and human user results attempting a \emph{block-pushing} task.  

\subsection{Human-Controlled Block-Pushing}

In previous work over 1000 human users completed this task using varying levels of feedback.
 The original experiment explored manipulation with varying amounts of sensing information: {\bf full-state} sensing showed the position of all robots; {\bf convex-hull} drew a convex hull around the outermost robots; {\bf mean} displayed the average position of the population; and {\bf mean + variance} added a confidence ellipse. Fig.~\ref{fig:Visualization} shows screenshots of the same robot swarm with each type of visual feedback. Full-state requires $2n$ data points for $n$ robots. Convex-hull requires at worst $2n$, but usually a smaller number.  Mean requires two, and variance three, data points.  Mean and mean + variance are convenient even with millions of robots. We hypothesized a steady decay in performance as the amount of visual feedback decreased.


\begin{figure}
\centering
\begin{overpic}[width = \columnwidth]{ResVaryVis.pdf}\end{overpic}
\vspace{-2em}
\caption{\label{fig:ResVaryVis} Completion-time results for the four levels of visual feedback shown in Fig.~\ref{fig:Visualization}. 
%\vspace{-2em}
}
\end{figure}

\begin{figure}[b!]
\renewcommand{\figwid}{0.24\columnwidth}
\begin{overpic}[width =\figwid]{VaryVisFS.pdf}\put(20,15){Full-state}\end{overpic}
\begin{overpic}[width =\figwid]{VaryVisCH.pdf}\put(10,15){Convex-hull}\end{overpic}
\begin{overpic}[width =\figwid]{VaryVisMV.pdf}\put(10,15){Mean + var}\end{overpic}
\begin{overpic}[width =\figwid]{VaryVisMe.pdf}\put(30,15){Mean}\end{overpic}
\vspace{-2em}
\caption{\label{fig:Visualization}Screenshots from a block-pushing task with human users. This experiment challenged players to quickly steer 100 robots (blue discs) to push an object (green hexagon) into a goal region. 
%\vspace{-1em}
}
\end{figure}

To our surprise, the results summarized in \ref{fig:ResVaryVis} indicated the opposite: players  with just the mean completed the task faster than those with full-state feedback.  As Fig.~\ref{fig:ResVaryVis} shows, the levels of feedback arranged by increasing completion time are [mean, mean + variance, full-state, convex-hull].  Interviews with  beta-testers suggests that tracking 100 robots was overwhelming---similar to schooling phenomenons that confuse predators---while working with just the mean + variance was like using a ``spongy'' manipulator. Convex-hull feedback was confusing and irritating because a single robot left behind an obstacle would distort the entire hull, obscuring the information about the majority of the swarm.
%obscuring what the rest of the swarm is doing.   


\subsection{Automated Block-Pushing}

\begin{algorithm}
\caption{Block-pushing controller for a robotic swarm.}\label{alg:BlockPushing}
\begin{algorithmic}[1]
\Require Knowledge of swarm mean $[\bar{x},\bar{y}]$, the moveable block's center of mass $\mathbf{b}$, a map of the environment, and the locations of all convex corners $\mathbf{C}$
\Require Robot distribution is unimodal
\Require Obstacle-free, straight-line path from swarm to moveable block
\State Compute $\mathbf{M}$, the distance to goal, with breadth-first search
\State Compute the gradient, $\nabla \mathbf{M}$
\State $\mathbf{C} \gets \mathrm{sort(\mathbf{C})}$ according to $-\mathbf{M}$
\While{$\mathbf{b}$ is not in goal region}
\State $\sigma^2 \gets \max{(\sigma_x,\sigma_y)}$
\If {$\sigma^2 > \sigma_{max}^2$}
\While{$\sigma^2 > \sigma_{min}^2$}
\State $\mathbf{c}_i \gets$ the nearest corner in $\mathbf{C}$ to $[\bar{x},\bar{y}]$
\State $ [x_{goal}, y_{goal}] \gets \mathbf{c}_i $
\If {$\mathbf{M}(\mathbf{b}) > \mathbf{M} (\mathbf{c}_i)$}
\State  $[x_{goal}, y_{goal}] \gets  \mathbf{c}_{i-1}$ 
\State Apply \eqref{eq:PDcontrolPosition} to move toward $[x_{goal}, y_{goal}]$
\EndIf
\EndWhile
\Else  
\State $[x_{goal}, y_{goal}] \gets \mathbf{b} - r_b \nabla \mathbf{M}(\mathbf{b})$ 
\EndIf
\State Apply \eqref{eq:PDcontrolPosition} to move toward $[x_{goal}, y_{goal}]$
\EndWhile
\end{algorithmic}
\end{algorithm}

\begin{figure}
\centering
\begin{overpic}[scale=0.2]{BFSMode.png}
\end{overpic}
\begin{overpic}[scale=0.2]{GradientMode.png}
\end{overpic}
\vspace{-2em}
\caption{\label{fig:BFSGradient}The BFS algorithm finds the shortest path for the moveable block (left), which is used to compute gradient vectors (right).
%\vspace{-2em}
}
\end{figure}


To solve this block-pushing task, we discretized the environment.  On this discretized grid we used breadth-first search to determine $\mathbf{M}$, the shortest distance from any grid cell to the goal, and generated a gradient map $\nabla \mathbf{M}$ toward the goal as shown in Fig.~\ref{fig:BFSGradient}.  The block's center of mass is at $\mathbf{b}$ and has radius $r_b$. The robots were then directed to assemble at  $\mathbf{b} - r_b \nabla \mathbf{M}(\mathbf{b})$ to push the block toward the goal location. We use the hybrid hysteresis-based controller in Alg.~\ref{alg:MeanVarianceControl}  to track the desired position, while maintaining sufficient robot density to move a block by switching to minimize variance whenever variance exceeds a set limit. The minimize variance control law \eqref{eq:PDcontrolVariance} is slightly modified to choose the nearest corner further from the goal than $\mathbf{b}$ with an obstacle-free straight-line path to $\mathbf{b}$. 
The control algorithm  for block-pushing is listed in Alg.~\ref{alg:BlockPushing}. 
Figure~\ref{fig:story} shows snapshots during an execution of this algorithm, and experimental results are summarized in Fig.~\ref{fig:AutoControlVaryN}.





\begin{figure*}
\centering
\renewcommand{\figwid}{0.4\columnwidth}
\begin{overpic}[width =\figwid]{story1.png}\put(6,15){T = 5 s}
\end{overpic}
\begin{overpic}[width =\figwid]{story2.png}\put(6,15){T = 12 s}
\end{overpic}
\begin{overpic}[width =\figwid]{story3.png}\put(6,15){T = 20 s}
\end{overpic}
\begin{overpic}[width =\figwid]{story4.png}\put(6,15){T = 25 s}
\end{overpic}
\begin{overpic}[width =\figwid]{story5.png}\put(6,15){T = 33 s}
\end{overpic}
\vspace{-1em}
\caption{\label{fig:story}Snapshots showing the block-pushing experiment under automatic control.  See the video attachment for an animation. 
%\vspace{-2em}
}
\end{figure*}







\begin{figure}
\centering
\begin{overpic}[width = \columnwidth]{AutoControlVaryN.pdf}\end{overpic}
\vspace{-2em}
\caption{\label{fig:AutoControlVaryN} Completion-time results using the automatic controller from Alg.~\ref{alg:BlockPushing} for different numbers of robots.  Each bar represents the results of five experiments.
}
\end{figure}


\todo{images of worlds where the algorithm fails, short discussion.}

\begin{figure}
\centering
\begin{overpic}[scale=0.2]{FailureBlockPush.png}
\end{overpic}
\begin{overpic}[scale=0.2]{FailureBlockPushing}
\end{overpic}
\vspace{-1em}
\caption{\label{fig:Failure}The algorithm fails when some robots are stock in the maze and the swarm can not reach min variance.%\vspace{-2em}
}
\end{figure}







